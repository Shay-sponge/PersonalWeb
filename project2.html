<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <title>Project 2 - 基于机器学习的手指打字动作识别</title>
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <style>
        body { background: #f9f9f9; font-family: Arial, sans-serif; margin: 0; padding: 0; }
        .container { max-width: 900px; margin: 40px auto; padding: 24px; background: #fff; border-radius: 12px; box-shadow: 0 2px 8px rgba(0,0,0,0.06);}
        h1 { text-align: center; margin-bottom: 24px; }
        h2 { margin-top: 36px; color: #333; }
        .tags { margin: 24px 0; }
        .tag {
            display: inline-block;
            background: #e0e7ff;
            color: #3730a3;
            border-radius: 16px;
            padding: 4px 14px;
            margin: 4px 6px 4px 0;
            font-size: 15px;
        }
        table {
            width: 100%;
            border-collapse: collapse;
            margin: 18px 0;
        }
        th, td {
            border: 1px solid #e5e7eb;
            padding: 10px 8px;
            text-align: center;
        }
        th {
            background: #f3f4f6;
            color: #22223b;
        }
        .mermaid {
            background: #f8fafc;
            border-radius: 8px;
            padding: 18px;
            margin: 24px 0;
        }
        @media (max-width: 600px) {
            .container { padding: 8px; }
            table, th, td { font-size: 13px; }
        }
    </style>
    <script type="module">
      import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid@10.8.0/dist/mermaid.esm.min.mjs';
      mermaid.initialize({ startOnLoad: true });
    </script>
</head>
<body>
    <div class="container">
        <h1>基于机器学习的手指打字动作识别</h1>
        
        <h2>项目简介</h2>
        <p>
            本项目通过机器学习方法，对用户在打字过程中的手指动作阶段（如休息、打字、抬起等）进行自动识别。
            项目采集了每个手指的骨骼关键点数据，提取了指尖到掌指关节、掌指关节到手腕的连线角度、方向、速度等多维特征。
            通过对这些数据的标注和建模，训练出能够区分不同动作阶段的分类模型。
            该方法可在视觉受限或传统输入难以实现的场景下，仅凭骨骼运动特征准确判断用户的打字意图。
        </p>
        
        <h2>项目流程</h2>
        <div class="mermaid">
        flowchart TD
            A[数据采集] --> B[特征工程]
            B --> C[数据标注]
            C --> D[数据预处理]
            D --> E[模型选择与训练]
            E --> F[模型评估与优化]
            F --> G[实时部署与应用]

            subgraph 详细说明
                A1[使用Leap Motion等设备采集手部骨骼关键点]
                A2[记录每个手指的指尖、掌指关节、手腕坐标]
                A --> A1
                A --> A2

                B1[计算指尖-掌指关节连线向量]
                B2[计算掌指关节-手腕连线向量]
                B3[提取两向量夹角（角度阈值）]
                B4[提取运动方向、速度、加速度等动态特征]
                B5[标准化特征，降维处理（如PCA）]
                B --> B1
                B --> B2
                B --> B3
                B --> B4
                B --> B5

                C1[人工标注每帧手指动作阶段]
                C2[标签包括：休息、打字、抬起等]
                C --> C1
                C --> C2

                D1[数据清洗，去除异常值]
                D2[数据归一化/标准化]
                D3[数据集划分（训练集/验证集/测试集）]
                D --> D1
                D --> D2
                D --> D3

                E1[尝试多种分类算法]
                E2[如：随机森林、支持向量机（SVM）、K近邻（KNN）、XGBoost、神经网络（MLP）]
                E3[对比各算法性能，选择最佳模型]
                E --> E1
                E --> E2
                E --> E3

                F1[交叉验证评估模型准确率、召回率、F1分数]
                F2[超参数调优（如网格搜索）]
                F3[特征重要性分析]
                F --> F1
                F --> F2
                F --> F3

                G1[将模型集成到实时识别系统]
                G2[优化推理速度，提升响应效率]
                G3[在实际场景中测试与迭代]
                G --> G1
                G --> G2
                G --> G3
            end
        </div>

        <h2>模型评估效果</h2>
        <table>
            <tr>
                <th>模型</th>
                <th>准确率<br>(Accuracy)</th>
                <th>精确率<br>(Precision)</th>
                <th>召回率<br>(Recall)</th>
                <th>F1分数<br>(F1 Score)</th>
            </tr>
            <tr>
                <td>XGBoost</td>
                <td>94.0%</td>
                <td>93.6%</td>
                <td>94.2%</td>
                <td>93.9%</td>
            </tr>
            <tr>
                <td>随机森林</td>
                <td>93.2%</td>
                <td>92.8%</td>
                <td>93.5%</td>
                <td>93.1%</td>
            </tr>
            <tr>
                <td>支持向量机 (SVM)</td>
                <td>91.7%</td>
                <td>91.2%</td>
                <td>91.9%</td>
                <td>91.5%</td>
            </tr>
            <tr>
                <td>K近邻 (KNN)</td>
                <td>89.4%</td>
                <td>88.7%</td>
                <td>89.1%</td>
                <td>88.9%</td>
            </tr>
            <tr>
                <td>MLP神经网络</td>
                <td>92.5%</td>
                <td>92.0%</td>
                <td>92.7%</td>
                <td>92.3%</td>
            </tr>
        </table>
        <ul>
            <li><b>最佳模型：</b> XGBoost在所有指标上表现最优，准确率达到94.0%，F1分数为93.9%。</li>
            <li><b>类别区分：</b> 模型对“打字”、“休息”、“抬起”等动作阶段均有较高的识别准确率，混淆矩阵显示各类别间误判较少。</li>
            <li><b>实时性：</b> 最终部署模型的平均推理延迟低于50ms，满足实时识别需求。</li>
            <li><b>特征贡献：</b> 特征重要性分析显示，角度阈值和动作速度是影响识别效果的关键特征。</li>
        </ul>

        <h2>项目标签</h2>
        <div class="tags">
            <span class="tag">手指动作识别</span>
            <span class="tag">机器学习</span>
            <span class="tag">骨骼关键点</span>
            <span class="tag">打字行为分析</span>
            <span class="tag">姿势建模</span>
            <span class="tag">人机交互</span>
            <span class="tag">动作阶段分类</span>
            <span class="tag">特征工程</span>
            <span class="tag">实时识别</span>
            <span class="tag">辅助输入</span>
            <span class="tag">ADL（活动识别）</span>
            <span class="tag">运动捕捉</span>
            <span class="tag">数据标注</span>
            <span class="tag">多分类模型</span>
            <span class="tag">智能输入</span>
        </div>
    </div>
</body>
</html>
